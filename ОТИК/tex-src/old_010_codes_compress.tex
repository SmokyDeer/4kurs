\input{commonpath}
\input{\ROOTPATH/commonpres}

\title{Кодирование. Сжатие данных. Форматы файлов}

% \title{Простые коды. Форматы файлов}
% \title{Сжатие данных. Сжатие без учёта контекста. Разделимые коды}


\def\UnicodeVersion{12.1}
\def\UnicodeSymCount{137\,994}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle


\input{\ROOTPATH/pres-sections/00_ss_code.tex}




\subsection{Сжатие}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-1.em}{-1.5em}
\small
\setlength{\leftmargini}{0em} 
\setlength{\parskip}{0.2\parskip} 

% Сжатие "--- удаление избыточности:
% $|code(X)|\to I(X)$ \mbox{(согласно~первой теореме Шеннона $|code(X)|\geqslant I(X)$).}

\termin{Сжатие} (компрессия, упаковка) "--- кодирование
$|code(X)| < |X|$, \mbox{причём $X$~однозначно} и~полностью восстанавливается по $code(X)$.

Согласно~первой теореме Шеннона $|code(X)|\geqslant I(X)$ (средние!).

Кодирование с~$|code(X)|\to I(X)$ и~$|code(x)|\to I(x)$ "--- \termin{оптимальное.}


\begin{enumerate}
\item Сжимается не отдельное сообщение $x$, а~источник $X$.
% \item Необходимо знать не только отдельное сообщение $x$, но и~его источник $X$.

\item Сжатие возможно только при наличии избыточности в~изначальном кодировании $X$ ($|X|>I(X)$).

\end{enumerate}

% Пусть $x$ "--- строка из $n$ октетов: $x = \chi_0, \ldots, \chi_{n-1}$;
% \mbox{источник~$X$ неизвестен.}
% 
% Если $X$ равновероятный (порождает каждую из~$N = 2^{8n}$ возможных строк длины $n$ с~вероятностью $\frac{1}{N}$), то $I(X) = \log_2(N) = 8n$ бит, то есть $n$ октетов.
% 
% То есть средняя длина кода $|code(X)|$ не может быть меньше $n$ ни для какого кодирования:
% \termin{любой алгоритм сжатия некоторые сообщения укорачивает, а~некоторые "--- удлиняет.}

% Свойства алгоритмов сжатия: а) степень сжатия в~наилучшем случае; б) сжатие/увеличение

Если источник~$X$ порождает блоки длины $N$ бит с~равной вероятностью $\left( p=\frac{1}{2^N} \right)$, он неизбыточен $\to$
% 
% $\to$ 
не~существует такого алгоритма сжатия, который сжимает \termin{любой} блок длины $N$.
% \smallskip
\medskip

Любой алгоритм сжатия сжимает часто встречающиеся блоки данных за счёт того, что более редкие увеличиваются в~размерах.

\end{adjustwidth}
\end{frame}




\subsection{Последовательность и её сжатие}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-1.5em}{-1.8em}
\setlength{\parskip}{0.\parskip}
\small
\setbeamertemplate{itemize/enumerate body begin}{\small\setlistspacing{1}{0.5ex}}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
% \setlength{\parskip}{\smallskipamount} 
% \small
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\leftmargini}{2ex} 


Источник $X$ генерирует \termin{входную последовательность} $C = c_1c_2\ldots c_n\ldots$, $c_i \in A$ "--- символы пронумерованы (есть~«предыду­щий» и~«последующий»).

$X$ неизвестен $\Rightarrow$ строится \termin{модель источника} по входной последовательности.
\medskip


\begin{enumerate}
\item \termin{блок} "--- конечная входная последовательность (произвольный доступ);

\item \termin{поток} "--- с~неизвестными границами (последо­вательный доступ).
\end{enumerate}


{Алгоритмы сжатия} по типу входной последовательности:
\vspace{-1.5\parskip}

\begin{enumerate}
\item блочные "--- статистика всего блока добавляется к~сжатому блоку;
\item поточные  (адаптивные)  "--- статистика вычисляется только для уже обработанной части потока, «на лету».
% ,  для уже обработанных данных. 

\end{enumerate}


\medskip


\termin{Свойства алгоритмов сжатия:}
\begin{enumerate}
\item степень сжатия $\frac{|X|}{|code(X)|}$ (в~среднем по источнику; $\frac{|X|}{|code(X)|} \leqslant \frac{|X|}{|I(X)|}$)
% $\left(\text{в~среднем по источнику;~} \frac{|X|}{|code(X)|} \geqslant \frac{|X|}{|I(X)|}\right)$
и~\termin{степень увеличения размера в~наихудшем случае;}

\item скорость сжатия и~разжатия. 
\end{enumerate}

\end{adjustwidth}
\end{frame}


% \subsection{Данные}
% 
% % \begingroup
% % \setbeamerfont{frametitle}{size=\linespread{1.0}\normalsize}
% % \subsection{Качественные и~количественные данные}
% \begin{frame}{\insertsubsection}
% \small
% \small\setlength{\parskip}{\smallskipamount} 
% 
% \termin{Качественные} данные "--- указатели на символы внутри таблиц или на ветви алгоритма (буквы, цифры, ноты, символы шахматных фигур, карточных мастей и~т.\,д.). 
% 
% \termin{Количественные} данные "---  записи значений каких-либо величин (элемен­ты мультимедийных данных и~т.\,д.).
% 
% % \termin{Код} "--- конечная последовательность битов, количество би­тов в~коде "--- длина кода.
% % \end{frame}
% % \endgroup
% 
% % \subsection{Алфавит}
% % \begin{frame}{\insertsubsection}
% % \small\setlength{\parskip}{\medskipamount} 
% 
% Конечная последовательность элементов "--- \termin{слово (строка, фраза)}, количество элементов в~слове "--- \termin{длина слова}.
% 
% \termin{Символ} "--- «атом» некоторого языка, содержащий качественную информацию.
% 
% 
% Множество всех различных символов, порождаемых некоторым источ­ником "--- \termin{алфавит},  количество символов в~этом множестве "--- размер алфавита.
% 
% % \termin{Источники данных} порождают только элементы,  \termin{физические} источники информации "--- символы или элементы.
% Алфавит до преобразования "--- первичный, алфавит конечного представления "--- вторичный
% \end{frame}


% % \section{Определения (сжатие)}
% % \section{Понятие сжатия}
% 
% \subsection{Сжатие}
% \begin{frame}{\insertsubsection}
% \small
% \setlength{\parskip}{\medskipamount} 
% 
% \termin{Сжатие (компрессия, кодиро­вание, упаковка)} блока "--- %такое его описание, при котором 
% создавае­мый сжатый блок содержит меньше битов, чем исходный, но по нему воз­можно однозначное восстановление каждого бита исходного блока.
% 
% Обрат­ный процесс, восстановление по описанию "--- \termin{разжатие (декомпрессия, декодирование, распаковка).}
% 
% % \end{frame}
% 
% \frametitlelikeleft{Эффективность сжатия}
% 
% % \subsection{Эффективность сжатия}
% % \begin{frame}{\insertsubsection}
% \begin{enumerate}
% 
% \item степень сжатия (отноше­ние длины несжатых данных к~длине соответствующих им сжатых данных),
% 
% \item скорость сжатия и~разжатия. 
% \end{enumerate}
% \end{frame}
% 
% \subsection{Первая теорема Шеннона (для~сжатия)}
% \begin{frame}{\insertsubsection}
% % \small
% \small
% 
% $$|code(X)|\geqslant I(X)$$
% При отсутствии помех 
% \termin{средняя длина двоичного кода} может быть сколь угодно близкой к~\termin{средней информации,} приходящейся на знак первичного алфавита. 
% 
% Для достаточно длинного сообщения $X$
% $$\forall \varepsilon>0 ~ \exists code:~ |code(X)|\leqslant I(X)+\varepsilon$$
% 
% \end{frame}
% 
% % 
% % \subsection{Классификация по порядку обработки}
% % \begin{frame}{\insertsubsection}
% % 
% % \begin{description}
% % \item[Адаптивные (поточные)]  "--- описание новых поступающих несжатых данных через уже обработанные. 
% % 
% % \item[Блочные] "--- статистика каждого блока данных высчитывается отдельно и~добавляется к~самому сжатому блоку.
% % \end{description}
% % 
% % % \begin{adjustwidth}{-1.5em}{-1.8em}
% % % \small
% % % 
% % % \termin{Преобразование потока} "--- описание новых поступающих несжатых данных через уже обработанные. 
% % % \\
% % % При этом не вычисляется никаких вероятностей, кодирование символов осуществляется только на основе тех данных, которые уже были обработаны.%, как например в~LZ – методах (названных по имени Абрахама Лемпеля и~Якоба Зива). В~этом случае, 
% % % Второе и~дальнейшие вхождения подстроки, уже известной кодировщику, заменяются ссылками на её первое вхождение.
% % % 
% % % \termin{Статистические методы сжатия}  делятся на \termin{адаптивные (поточные)} и~\termin{блочные.}
% % % В~первом (адаптивном) варианте, вычисление вероятностей для новых данных происходит по данным, уже обработанным при кодировании. К~этим методам относятся адаптивные варианты алгоритмов Хаффмана и~Шеннона-Фано.
% % % Во втором (блочном) случае, статистика каждого блока данных высчитывается отдельно, и~добавляется к~самому сжатому блоку. Сюда можно отнести статические варианты методов Хаффмана, Шеннона-Фано, и~арифметического кодирования.
% % % 
% % % \termin{Методы преобразования блока.} Входящие данные разбиваются на блоки, которые затем трансформируются целиком. При этом некоторые методы, особенно основанные на перестановке блоков, могут не приводить к~существенному (или вообще какому-либо) уменьшению объёма данных. Однако после подобной обработки, структура данных значительно улучшается, и~последующее сжатие другими алгоритмами проходит более успешно и~быстро.
% % % 
% % % \end{adjustwidth}
% % \end{frame}
% 


% \subsection{Кодирование}
% \begin{frame}{\insertsubsection}
% \setlength{\leftmargini}{0pt}
% 
% % Какие же могут быть особенности вторичного алфавита при кодировании:
% \begin{itemize}
% \item Элементарные коды 0 и 1 могут иметь одинаковые или разные длительности.
% 
% \item Длина кода может быть одинаковой для всех знаков первичного алфавита (код равномерный) или различной (неравномерный код).
% 
% \item Коды могут строиться для отдельного знака первичного алфавита (алфавитное кодирование) или для их комбинаций (кодирование блоков, слов). 
% \end{itemize}
% \end{frame}

% \subsection{Методы сжатия}
% \begin{frame}{\insertsubsection}
% % \section{Методы сжатия}
% % \begin{frame}{\insertsection}
% 
% % \subsection{Классификация по принципу работы}
% % \begin{frame}{\insertsubsection}
% \small
% % http://articles.org.ru/docum/compress.php
% 
% \begin{description}[С]
% 
% \item[\termin{Статистические методы}] "--- каждый символ заменяется некоторым кодом так, чтобы наиболее частым символам соответствовали более короткие коды.
% \begin{itemize}
% \item код Шеннона"--~Фано;
% \item код Хаффмана;
% \item неалфавитное кодирование: арифметический код.
% \end{itemize}
% 
% \item[\termin{Словарные методы}] "--- составляют текст из кусочков исходного файла в~той или иной форме.\\
% % \termin{Словом} называется некоторая последовательность символов (байтов).\\
% % \termin{Словарь} содержит некоторое количество слов.\\
% % Сжатие достигается за счёт того, что номер слова в~словаре обычно гораздо короче самого слова. 
% % Словарные методы отличаются высокой скоростью сжатия/распаковки, но несколько худшим сжатием. 
% \begin{itemize}
% \item  кодирование длин повторений (Run Length Encoding, RLE).
% 
% \item коды Зива"--~Лемпеля  (LZ77, LZ78).
% 
% \end{itemize}
% \end{description}
% 
% \end{frame}



% \subsection{Карта групп методов сжатия}
% \begingroup
% \renewcommand{\tabularxcolumn}{m}
% \begin{frame}{\insertsubsection}
% \begin{adjustwidth}{-1.5em}{-1.8em}
% \small
% \begin{tabularx}{1\linewidth}{|>{\raggedright\arraybackslash}m{0.24\linewidth}@{}|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|}\hline
% & \multicolumn{2}{c|}{Статистические}	& \multicolumn{2}{c|}{Преобразующие}	\\\hline
% & Поточные & Блочные &  Поточные & Блочные	\\\hline
% Для «слов», модель «Источник с памятью»	&
% CM, DMC, все РРМ	& CMBZ, pre­conditioned PPMZ	& Все LZ, в~т.\,ч.~LZH и LZW	& ST, в~т.\,ч.~BWT	\\\hline
% Для «элементов», модели «Источник без памяти» или «Анало­говый сигнал»	&
% Адаптив­ный HUFF	& Статиче­ский HUFF	& SEM, VQ, MTF, DC, SC, DWT	& DCT, FT, фрак­тальные методы	\\\hline
% Для «элементов» или «битов»	&
% Адаптив­ный ARIC	& Статиче­ский ARIC	& RLE, LPC, в~т.\,ч.~дельта	& PBS, ENUC	\\\hline
% 
% \end{tabularx}
% \end{adjustwidth}
% \end{frame}
% \endgroup


% \subsection{Простейшие алгоритмы сжатия}
% \begin{frame}{\insertsubsection}
% \begin{frame}{\insertsection}
% \begin{adjustwidth}{-1em}{-1.8em}
% 
% \begin{itemize}
% \item Источников данных без памяти:
% \begin{itemize}
% \item код Шеннона"--~Фэно;
% \item код Хаффмана;
% \item арифметический код.
% \end{itemize}
% 
% \item Источников типа «Анало­говый сигнал» "--- кодирование длин повторений (Run Length Encoding, RLE).
% 
% \item Словарного сжатия "--- LZ77.
% 
% \end{itemize}
% \end{adjustwidth}
% \end{frame}




\subsection{Оптимальное кодирование источника $X$}
\begin{frame}{\insertsubsection}
% \begin{adjustwidth}{-1.em}{-1.5em}
\small
\setlength{\leftmargini}{0em} 
\setlength{\parskip}{0.3\parskip} 

Пусть $X$ порождает последовательность из $2^N$ возможных символов.

\begin{enumerate}
\item Равновероятный источник ($I(X)=N$) "--- кодирование отдельных символов кодами фиксированной ширины $N$ бит.
% (нет избыточности).

\item Стационарный источник без~памяти, порождающий символы с~разными постоянными вероятностями ($I(X)<N$) "--- кодирование отдельных символов кодами переменной ширины: коды Хаффмана, методы~семейства арифметического кодирования.

\item Стационарный источник с~памятью, порождающий символы с~вероятностями, зависящими от контекста ($I(X)<N$) "--- кодирование сочетаний символов: словарные методы \mbox{семейства LZ77 (словарь=текст)} и~семейства LZ78 (отдельный словарь в~виде дерева/таблицы).

\end{enumerate}

Если изначально каждый символ записан кодом фиксированной ширины из $N$ бит $\Rightarrow$ сжатие для \enumilike{2} и~\enumilike{3}.

% Степень сжатия $\frac{|X|}{|code(X)|}$ оценивается на некоторой выборке файлов;

% \end{adjustwidth}
\end{frame}



\section{Модель источника}


\subsection{Модель источника: $X$ неизвестен}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-1.em}{-1.5em}

% \def\msg{\chi}
\def\msg{x}


\small
\setbeamertemplate{itemize/enumerate body begin}{\small}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\leftmargini}{0em} 
% \setlength{\leftmarginii}{0.5em} 
\setlength{\leftmarginii}{1em} 

\setlength{\parskip}{\smallskipamount} 
\smallskip

Оценка алфавита $A_1$ и~вероятностей %$p(a)$ 
источника по сообщению: 
% обороноспособность (18)
$\msg = $\termin{«молоко»}
% (6) $ = c_1, c_2, c_3, c_4, c_5, c_6$

\begin{enumerate}

\item $A_1$ "--- koi-8, равновероятные символы: $p =
% p(\text{к}) = p(\text{л})  = p(\text{м})= p(\text{о}) = 
\frac{1}{256}$, $I(\msg) = 6\cdot \log_2(256) = 48$ \rlap{(бит)}
\smallskip

\item $A_1$ "--- русский алфавит, равновероятные: $p%(\text{к}) = \ldots 
= \frac{1}{33}$, $I(\msg) = 6\cdot \log_2(33) \approx 30,3$ 
\smallskip

\item $A_1$ "--- Unicode {\UnicodeVersion}, равновероятные: $p = \frac{1}{\UnicodeSymCount}, I(\msg)\approx 6\cdot 17,1  \approx 102,4$ 
\smallskip

\item $A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$, равновероятные: 
% $p(\text{к}) = \ldots = \frac{1}{4}$
$p = \frac{1}{4}$, $I(\msg) = 6\cdot \log_2(4) = 12$ 
\medskip

\item $A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$ или koi-8, неравновероятные, стац-й источник без памяти:
%\termin{Источник без памяти} "--- предполагаем $p(c_i = a) = p(a) = const$ для~всех $i$ и~всех $a \in A_1$:

о (3) + к (1) + л (1) + м (1): \hfill $p(\text{о}) = \frac{3}{6}, \hfill p(\text{к}) = p(\text{л})  = p(\text{м})= \frac{1}{6}$

$I(\msg) = - 3\cdot \log_2(\frac{3}{6}) - \log_2(\frac{1}{6})- \log_2(\frac{1}{6})- \log_2(\frac{1}{6}) = 3\cdot \log_2(2) + 3\cdot \log_2(6)
\approx 10,8$%
\medskip

\item 
$A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$ или koi-8, 
% неравновероятные символы, память на 1~символ:
марковский источник первого порядка:
% $p(c_i=a) = p(a,c_{i-1})$:

$
\begin{array}{@{}l|c|c|c|c|@{}}
% c_{i-1}&p(c_i=\text{к})&p(c_i=\text{л})&p(c_i=\text{м})&p(c_i=\text{о})\\\hline
\text{предыдущий}&p(\text{к})&p(\text{л})&p(\text{м})&p(\text{о})\\\hline
-&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\\\hline
\text{к, л, м}&0&0&0&1\\\hline
% \text{л}&0&0&0&1\\\hline
% \text{м}&0&0&0&1\\\hline
\text{о}&\frac{1}{2}&\frac{1}{2}&0&0\\\hline
\end{array}
$\hfill$\begin{array}{@{}c@{}}
I(\msg) = - \log_2(\frac{1}{4}) - \log_2(1) -\\
- \log_2(\frac{1}{2})- \log_2(1)-\\- \log_2(\frac{1}{2})- \log_2(1) =\\ = 2 + 1 + 1 = 4
\end{array}
$\hfill\strut
\smallskip
\item $A_1 = \{\text{молоко}, \text{чай}\}$, равновероятные символы: $p = \frac{1}{2}, I(\msg) = 1$ 
\smallskip

\item $A_1 = \{\text{молоко}\}$: $p = 1, I(\msg) = 0$ 
\end{enumerate}

% всего: 
% о (7) + с (3) + б (2) + н (2) + п (1) + р (1) + т (1) + ь (1)

% полагаем 
% $p(\text{о}) = \frac{7}{18}, p(\text{с}) = \frac{3}{18}, p(\text{б}) = p(\text{н}) = \frac{2}{18}, p(\text{п}) = p(\text{р}) = p(\text{т}) = p(\text{ь}) = \frac{1}{18}$

% \termin{Источник с~памятью} "--- предполагаем $p(c_i = a) = p(a, c_{i-1}, c_{i-2}, \ldots)$

% после «о»: 
% об, ор, он, ос (3): $p(\text{с}|\text{о}) = \frac{3}{6}, p(\text{б}|\text{о}) = p(\text{р}|\text{о}) =p(\text{н}|\text{о}) =\frac{1}{6}$\\
% $p(\text{о}|\text{о}) = p(\text{п}|\text{о}) =p(\text{т}|\text{о})=p(\text{ь}|\text{о}) =0$

% бо, бн:
% 
% ро:
% 
% но (2):
% 
% сп, со, ст:
% 
% по:
% 
% ть:



\end{adjustwidth}

% \termin{Источники данных} порождают только элементы,  \termin{физические} источники информации "--- символы или элементы.
\end{frame}

\subsection{Задачи}
\begin{frame}{\insertsubsection}
\small

Оценить алфавит и~построить модели источника: а) равновероятную, б) стационарную без памяти, в) марковскую первого порядка для сообщения $x$,
по модели оценить  $I(x)$ и~$I(y)$.

\begin{enumerate}

\item $x = \text{хрюхрюхрюмяухрюмяумяухрюмяумяу}$ (30 символов, 5~«хрю» и~5 «мяу» 0001011011); $y=\text{рюх}$.

\item $x = \text{кукукукукарекукукукарекукукарекукукукарекукукареку}$ (50~символов, 5~«ку» и~5~«кукареку» аналогично); $y=\text{кар}$.

\end{enumerate}

\end{frame}

% \section{Кодирование}



% \subsection{Формальное представление информации}
% \begin{frame}{\insertsubsection}
% % \section{Формальное представление знаний}
% % \begin{frame}{\insertsection}
% % \small
% \setlength{\parskip}{0.5\parskip}
% 
% При формальном представлении %знаний 
% каждому описываемому объекту или понятию ставится в~соответствие %некоторый
% \emph{числовой код.}
% % \\
% % Связи %между кодируемыми сущностями 
% % также представляются кодами (адресами и~указателями).
% 
% 
% % % Информация может быть двух видов: 
% % \begin{tabularx}{\linewidth}{lL}
% % Виды:&
% % \begin{itemize}
% % \item дискретная (цифровая) информация;
% % \item непрерывная (аналоговая).
% % \end{itemize}
% % \end{tabularx}
% 
% % {\terminblue
% % Виды информации: непрерывная (аналоговая) %(цифровая) 
% % \rlap{и~дискретная.}
% % 
% % }
% 
% Для формализации дискретных данных
% % Для перевода неформальных данных
% % в формальный, цифровой вид 
% % должны использоваться специальные 
% используются \termin{таблицы кодировки.}
% % сопоставляющие кодируемым сущностям их коды.
% 
% Формализация %аналогового
% непрерывного
% сигнала  "--- оцифровка.
% 
% 
% \end{frame}



\subsection{Характеристики кодов}
\begin{frame}{\insertsubsection}
\small
\setbeamertemplate{itemize/enumerate body begin}{\small}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\leftmargini}{0ex} 

% Свойства кодов
\begin{enumerate}
% \item Перв\tikz[remember picture] \node[coordinate,yshift=0em] (n0) {};ичный 
% и~вторичный алфавиты ($A_2 = \{0, 1\}$ "--- двоичный код) 

\item Первичный алфавит $A_1$\tikz[remember picture] \node[coordinate,yshift=0.5em] (n1) {}; 
        
\item Оптимальность (неизбыточность) 
\item Избыточность (в том числе помехоустойчивость) \tikz[remember picture] \node[coordinate] (n2) {};

\item Вторичный алфавит $A_2$ ($A_2 = \{0, 1\}$ "--- двоичный код) 
\item Однозначная декодируемость

\item Разделяемость
"---
код $code(x)$ любой последовательности \rlap{$x = \overline{a_1\ldots a_n}% \in A_1^+
$}\\
единственным образом разделим на кодовые слова
\rlap{$c_i = code(a_i), a_i \in A_1$:}

% Возможно однозначно выделить коды отдельных символов первичного алфавита.
\begin{enumerate}
\item коды фиксированной ширины "--- $a, b, c \to {}$ $00$, $01$, $10$;
\item коды с~разделителем "--- $1$, $11$, $111$ ($0$ как разделитель символов);
\item префиксные коды (дерево) "--- $0$, $10$, $11$; %"--- ни один $c_i$ не является началом другого
\item прочие "--- например, $11, 1110111, 11100111$.
% \hfill\texttime{16:00}

\end{enumerate}
\end{enumerate}

% ? собирать 2 раза, а то скобка не там
  \begin{tikzpicture}[overlay,remember picture]
%       \path (n2) -| node[coordinate] (n3) {} (n1);
      \draw[thick,decorate,decoration={brace,amplitude=3pt}]
%             (n1) -- (n3) 
            (n1-|n2) -- (n2) 
            node[midway, right=4pt] (text) {модель источника!};
%         \draw[blockarrow] (text.west) --  (n0);
  \end{tikzpicture}



\end{frame}

% \subsection{Разделимые коды}
% \begin{frame}{\insertsubsection}
% % Любая последовательность
% % кодовых слов 
% % единственным образом разделима на кодовые слова
% Код любой последовательности $x \in A_1^+$
% единственным образом разделим на кодовые слова
% $c_i = code(a_i), a_i \in A_1$
% 
% % Возможно однозначно выделить коды отдельных символов первичного алфавита.
% \begin{enumerate}
% \item Коды фиксированной ширины
% \item Префиксные коды (дерево)
% \item Коды с~разделителем
% \item Прочие
% \end{enumerate}
% \end{frame}

\subsection{Задачи}
\begin{frame}{\insertsubsection}

Построить разделимые коды
% $\{a, b, c\} \to \{0, 1\}$:
для $A_1=\{a, b, c, d, e\}$,  $A_2=\{0, 1\}$:

\begin{itemize}
\item фиксированной ширины;
\item префиксный;
% \item «суффиксный»;
\item «постфиксный»;
\item с~разделителем;
\item не относящийся ни к~одной категории.
\end{itemize}

\end{frame}


% % \subsection{Неравенство Крафта"--~Макмиллана}
% \subsection{Неравенство Крафта--Макмиллана}
% % http://www.codingtheory.nsu.ru/seminars/seminar%2010.pdf
% \begin{frame}{\insertsubsection}
% Пусть $L = {\ell_{1},\ldots,\ell_{k}}$ "---
% множество длин кодовых слов.
% $$\sum _{i=1}^{k}q^{-\ell_{i}}\leqslant 1$$
% "--- необходимо и достаточно  для существования
% $q$-значных префиксного и~разделимого кодов с заданным набором длин~$L$.
% 
% \end{frame}













\section{Коды и~структура данных}

\input{\ROOTPATH/pres-sections/00_code_header.tex}





% \section{Представление данных}
% \input{\ROOTPATH/pres-sections/00_code_header.tex}


\input{\ROOTPATH/pres-sections/01_simplecodes.tex}

\makethanks
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
